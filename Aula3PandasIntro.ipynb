{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Pandas e manipulação de arquivos com Pandas\n",
    "\n",
    "- Introdução ao Pandas\n",
    "    - Conceitos Básicos de Pandas\n",
    "      - Estruturas de dados: Series e DataFrames\n",
    "      - Criação de Series e DataFrames a partir de listas e dicionários\n",
    "      - Visualização de dados: cabeçalho, cauda e informações básicas\n",
    "- Manipulação de Dados com Pandas\n",
    "    - Carregamento de Dados\n",
    "      - Leitura de dados de diferentes fontes (CSV, Excel, SQL) \n",
    "      - Visualização inicial e sumário estatístico\n",
    "    - Limpeza e Preparação de Dados\n",
    "      - Tratamento de valores ausentes\n",
    "      - Remoção de duplicatas\n",
    "      - Filtragem de dados  \n",
    "    - Transformação de Dados\n",
    "      - Operações com colunas (adicionar, remover, modificar)\n",
    "      - Funções de mapeamento\n",
    "      - Agrupamento e agregação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "- Fornecer uma compreensão abrangente da biblioteca Pandas, uma ferramenta essencial no Python para análise de dados. Ao final do curso, você será capaz de manipular, limpar e explorar conjuntos de dados de forma eficiente. Estaremos cobrindo desde a configuração do ambiente de desenvolvimento até a realização de análises de dados complexas e visualização de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visão Geral do Pandas e sua Importância\n",
    "- Pandas é uma biblioteca de código aberto que fornece estruturas de dados de alto desempenho e ferramentas de análise de dados para a linguagem Python. \n",
    "- Com Pandas, você pode realizar tarefas essenciais de __pré-processamento__ e __análise de dados__, como a __limpeza de dados__, transformações, agregações, e muito mais. \n",
    "- A biblioteca é amplamente utilizada em diversas áreas, incluindo finanças, neurociência, economia, estatística, publicidade e web analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de Implementação Inicial com Pandas:\n",
    "- Vamos começar com um exemplo simples para demonstrar como iniciar com o Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criando um DataFrame simples\n",
    "data = {\n",
    "    'Nome': ['João', 'Ana', 'Pedro', 'Maria'],\n",
    "    'Idade': [28, 34, 29, 32],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df, \"\\n\", \"_\"*50, \"\\n\")\n",
    "\n",
    "# Em notebooks o que é retornado da célula é renderizado (exibido) na saída da célula de código, não exigindo a função print\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria um DataFrame, que é uma das principais estruturas de dados do Pandas. \n",
    "\n",
    "Um DataFrame é semelhante a uma tabela de banco de dados ou uma planilha de Excel, com linhas e colunas. \n",
    "\n",
    "No exemplo acima, criamos um DataFrame a partir de um dicionário de listas, uma estrutura de dados muito comum em Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séries e DataFrames\n",
    "- Series: Uma Series é uma coluna unidimensional capaz de armazenar qualquer tipo de dados (inteiros, strings, floats, objetos Python, etc.). Cada elemento de uma Series é indexado, começando por padrão do índice 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criando uma Series a partir de uma lista\n",
    "idades = pd.Series([25, 30, 35, 40])\n",
    "print(idades)\n",
    "\n",
    "print(idades[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vals = [1, 7, 2, 7, 2, 9, 5]\n",
    "\n",
    "minha_serie = pd.Series(vals, index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])\n",
    "\n",
    "print(minha_serie)\n",
    "\n",
    "print(minha_serie[\"f\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aluno1    5\n",
      "aluno2    7\n",
      "aluno3    2\n",
      "aluno4    7\n",
      "aluno5    2\n",
      "aluno6    9\n",
      "aluno7    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "frequencia = {\"aluno1\": 5, \"aluno2\": 7, \"aluno3\": 2, \"aluno4\": 7, \"aluno5\": 2, \"aluno6\": 9, \"aluno7\": 5}\n",
    "\n",
    "diario = pd.Series(frequencia)\n",
    "print(diario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aluno2    7\n",
      "aluno4    7\n",
      "aluno6    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "frequencia = {\"aluno1\": 5, \"aluno2\": 7, \"aluno3\": 2, \"aluno4\": 7, \"aluno5\": 2, \"aluno6\": 9, \"aluno7\": 5}\n",
    "\n",
    "diario = pd.Series(frequencia, index = [\"aluno2\", \"aluno4\", \"aluno6\"])\n",
    "\n",
    "print(diario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrames: Um DataFrame é uma estrutura de dados bidimensional, como uma planilha ou uma tabela de banco de dados, com colunas de diferentes tipos. Pode ser visto como um conjunto de Series que compartilham o mesmo índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Cidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>28</td>\n",
       "      <td>São Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruno</td>\n",
       "      <td>34</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>29</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>32</td>\n",
       "      <td>Porto Alegre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fernando</td>\n",
       "      <td>45</td>\n",
       "      <td>Brasília</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nome  Idade          Cidade\n",
       "0       Ana     28       São Paulo\n",
       "1     Bruno     34  Rio de Janeiro\n",
       "2    Carlos     29  Belo Horizonte\n",
       "3     Diana     32    Porto Alegre\n",
       "4  Fernando     45        Brasília"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um DataFrame a partir de um dicionário de listas\n",
    "data = {\n",
    "    'Nome': ['Ana', 'Bruno', 'Carlos', 'Diana','Fernando'],\n",
    "    'Idade': [28, 34, 29, 32, 45],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'Brasília']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Series e DataFrames\n",
    "- A partir de __listas__: Podemos criar uma Series diretamente de uma lista. Para criar um DataFrame a partir de listas, podemos combinar várias listas em um dicionário, onde cada chave se torna o nome da coluna.\n",
    "- A partir de __dicionários__: Um DataFrame também pode ser criado a partir de um dicionário de listas ou de Series, proporcionando uma forma intuitiva de especificar dados junto com seus rótulos de coluna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização de Dados\n",
    "- Pandas oferece métodos simples para uma rápida inspeção dos seus dados.\n",
    "- Ferramentas cruciais para uma primeira análise exploratória dos dados, permitindo uma visão geral rápida e eficiente da estrutura e conteúdo do seu conjunto de dados.\n",
    "\n",
    "Métodos <code>.head() e .tail()</code>: Use df.head(n) para visualizar as primeiras n linhas do DataFrame df, e df.tail(n) para as últimas n. Se n não for especificado, o padrão é 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fernando\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Cidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>28</td>\n",
       "      <td>São Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruno</td>\n",
       "      <td>34</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>29</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>32</td>\n",
       "      <td>Porto Alegre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fernando</td>\n",
       "      <td>45</td>\n",
       "      <td>Brasília</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nome  Idade          Cidade\n",
       "0       Ana     28       São Paulo\n",
       "1     Bruno     34  Rio de Janeiro\n",
       "2    Carlos     29  Belo Horizonte\n",
       "3     Diana     32    Porto Alegre\n",
       "4  Fernando     45        Brasília"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Nome': ['Ana', 'Bruno', 'Carlos', 'Diana','Fernando','João', 'Ana', 'Pedro', 'Maria', 'Alice', 'Bob', 'Charlie'],\n",
    "    'Idade': [28, 34, 29, 32, 45, 28, 34, 29, 32,25, 30, 35],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'Brasília','São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'New York', 'Paris', 'London']\n",
    "}\n",
    "\n",
    "print(data['Nome'][4])\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "df.head()  # Mostra as primeiras 5 linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "       Nome  Idade          Cidade\n",
      "0       Ana     28       São Paulo\n",
      "1     Bruno     34  Rio de Janeiro\n",
      "2    Carlos     29  Belo Horizonte\n",
      "3     Diana     32    Porto Alegre\n",
      "4  Fernando     45        Brasília\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Cidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>28</td>\n",
       "      <td>São Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruno</td>\n",
       "      <td>34</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>29</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>32</td>\n",
       "      <td>Porto Alegre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fernando</td>\n",
       "      <td>45</td>\n",
       "      <td>Brasília</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nome  Idade          Cidade\n",
       "0       Ana     28       São Paulo\n",
       "1     Bruno     34  Rio de Janeiro\n",
       "2    Carlos     29  Belo Horizonte\n",
       "3     Diana     32    Porto Alegre\n",
       "4  Fernando     45        Brasília"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(df.tail()) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fernando'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('*'*80)\n",
    "\n",
    "#localizar uma linha\n",
    "df.loc[4]\n",
    "\n",
    "# df['Nome'][4]\n",
    "\n",
    "df['Nome'].loc[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "     Nome  Idade          Cidade\n",
      "2  Carlos     29  Belo Horizonte\n",
      "5    João     28       São Paulo\n",
      "8   Maria     32    Porto Alegre\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('*'*80)\n",
    "\n",
    "#localizar varias linhas - usando [[]] o resultado é um DataFrame\n",
    "print(df.loc[[2,5,8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Operações básicas de manipulação de dados com Pandas, como seleção de colunas, filtragem de linhas, e cálculos simples (médias, somas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Nome  Idade          Cidade\n",
      "0       Ana     28       São Paulo\n",
      "1     Bruno     34  Rio de Janeiro\n",
      "2    Carlos     29  Belo Horizonte\n",
      "3     Diana     32    Porto Alegre\n",
      "4  Fernando     45        Brasília\n",
      "********************************************************************************\n",
      "0         Ana\n",
      "1       Bruno\n",
      "2      Carlos\n",
      "3       Diana\n",
      "4    Fernando\n",
      "Name: Nome, dtype: object\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "33.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Cidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruno</td>\n",
       "      <td>34</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>32</td>\n",
       "      <td>Porto Alegre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fernando</td>\n",
       "      <td>45</td>\n",
       "      <td>Brasília</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nome  Idade          Cidade\n",
       "1     Bruno     34  Rio de Janeiro\n",
       "3     Diana     32    Porto Alegre\n",
       "4  Fernando     45        Brasília"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(df)\n",
    "\n",
    "print('*'*80)\n",
    "# Seleção de colunas\n",
    "print(df['Nome'])\n",
    "\n",
    "print('*'*80)\n",
    "# Filtragem de linhas\n",
    "new_df = df[df['Idade'] > 30]\n",
    "\n",
    "print('*'*80)\n",
    "# Cálculos simples\n",
    "print(df['Idade'].mean())\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>.info()</code>: Este método fornece um resumo conciso do DataFrame, incluindo o número de entradas não-nulas em cada coluna, o tipo de dados e o uso de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Duration  32 non-null     int64  \n",
      " 1   Date      31 non-null     object \n",
      " 2   Pulse     32 non-null     int64  \n",
      " 3   Maxpulse  32 non-null     int64  \n",
      " 4   Calories  30 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 1.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Date</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/01'</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>409.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/02'</td>\n",
       "      <td>117</td>\n",
       "      <td>145</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/03'</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/04'</td>\n",
       "      <td>109</td>\n",
       "      <td>175</td>\n",
       "      <td>282.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/05'</td>\n",
       "      <td>117</td>\n",
       "      <td>148</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/06'</td>\n",
       "      <td>102</td>\n",
       "      <td>127</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/07'</td>\n",
       "      <td>110</td>\n",
       "      <td>136</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>450</td>\n",
       "      <td>'2020/12/08'</td>\n",
       "      <td>104</td>\n",
       "      <td>134</td>\n",
       "      <td>253.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>'2020/12/09'</td>\n",
       "      <td>109</td>\n",
       "      <td>133</td>\n",
       "      <td>195.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/10'</td>\n",
       "      <td>98</td>\n",
       "      <td>124</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/11'</td>\n",
       "      <td>103</td>\n",
       "      <td>147</td>\n",
       "      <td>329.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/12'</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>250.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/12'</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>250.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/13'</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>345.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/14'</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>379.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/15'</td>\n",
       "      <td>98</td>\n",
       "      <td>123</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/16'</td>\n",
       "      <td>98</td>\n",
       "      <td>120</td>\n",
       "      <td>215.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/17'</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/18'</td>\n",
       "      <td>90</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/19'</td>\n",
       "      <td>103</td>\n",
       "      <td>123</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/20'</td>\n",
       "      <td>97</td>\n",
       "      <td>125</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/21'</td>\n",
       "      <td>108</td>\n",
       "      <td>131</td>\n",
       "      <td>364.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>119</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/23'</td>\n",
       "      <td>130</td>\n",
       "      <td>101</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/24'</td>\n",
       "      <td>105</td>\n",
       "      <td>132</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/25'</td>\n",
       "      <td>102</td>\n",
       "      <td>126</td>\n",
       "      <td>334.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>20201226</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/27'</td>\n",
       "      <td>92</td>\n",
       "      <td>118</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/28'</td>\n",
       "      <td>103</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/29'</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/30'</td>\n",
       "      <td>102</td>\n",
       "      <td>129</td>\n",
       "      <td>380.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/31'</td>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration          Date  Pulse  Maxpulse  Calories\n",
       "0         60  '2020/12/01'    110       130     409.1\n",
       "1         60  '2020/12/02'    117       145     479.0\n",
       "2         60  '2020/12/03'    103       135     340.0\n",
       "3         45  '2020/12/04'    109       175     282.4\n",
       "4         45  '2020/12/05'    117       148     406.0\n",
       "5         60  '2020/12/06'    102       127     300.0\n",
       "6         60  '2020/12/07'    110       136     374.0\n",
       "7        450  '2020/12/08'    104       134     253.3\n",
       "8         30  '2020/12/09'    109       133     195.1\n",
       "9         60  '2020/12/10'     98       124     269.0\n",
       "10        60  '2020/12/11'    103       147     329.3\n",
       "11        60  '2020/12/12'    100       120     250.7\n",
       "12        60  '2020/12/12'    100       120     250.7\n",
       "13        60  '2020/12/13'    106       128     345.3\n",
       "14        60  '2020/12/14'    104       132     379.3\n",
       "15        60  '2020/12/15'     98       123     275.0\n",
       "16        60  '2020/12/16'     98       120     215.2\n",
       "17        60  '2020/12/17'    100       120     300.0\n",
       "18        45  '2020/12/18'     90       112       NaN\n",
       "19        60  '2020/12/19'    103       123     323.0\n",
       "20        45  '2020/12/20'     97       125     243.0\n",
       "21        60  '2020/12/21'    108       131     364.2\n",
       "22        45           NaN    100       119     282.0\n",
       "23        60  '2020/12/23'    130       101     300.0\n",
       "24        45  '2020/12/24'    105       132     246.0\n",
       "25        60  '2020/12/25'    102       126     334.5\n",
       "26        60      20201226    100       120     250.0\n",
       "27        60  '2020/12/27'     92       118     241.0\n",
       "28        60  '2020/12/28'    103       132       NaN\n",
       "29        60  '2020/12/29'    100       132     280.0\n",
       "30        60  '2020/12/30'    102       129     380.3\n",
       "31        60  '2020/12/31'     92       115     243.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>.describe()</code>: Oferece uma visão geral estatística das colunas numéricas, como contagem, média, desvio padrão, mínimos e máximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.437500</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>304.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.039591</td>\n",
       "      <td>7.832933</td>\n",
       "      <td>12.998759</td>\n",
       "      <td>66.003779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>195.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>250.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>291.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>343.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>479.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Duration       Pulse    Maxpulse    Calories\n",
       "count   32.000000   32.000000   32.000000   30.000000\n",
       "mean    68.437500  103.500000  128.500000  304.680000\n",
       "std     70.039591    7.832933   12.998759   66.003779\n",
       "min     30.000000   90.000000  101.000000  195.100000\n",
       "25%     60.000000  100.000000  120.000000  250.700000\n",
       "50%     60.000000  102.500000  127.500000  291.200000\n",
       "75%     60.000000  106.500000  132.250000  343.975000\n",
       "max    450.000000  130.000000  175.000000  479.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatistica básica\n",
    "\n",
    "- mean(): Calcula a média dos valores em uma coluna (soma de todos os valores dividida pelo número de valores).\n",
    "\n",
    "- mode(): Calcula o valor mais frequente dos valores em uma coluna (o valor que aparece com maior frequência em uma coluna).\n",
    "\n",
    "- median(): Calcula a mediana dos valores em uma coluna (o valor que divide a coluna em duas partes iguais).\n",
    "\n",
    "- std(): Calcula o desvio padrão dos valores em uma coluna (raiz quadrada da soma dos quadrados das diferenças entre cada valor e a média dividida pelo número de valores).\n",
    "\n",
    "- count(): Conta o número de valores não-nulos em uma coluna.\n",
    "\n",
    "- min(): Calcula o valor mínimo dos valores em uma coluna.\n",
    "\n",
    "- max(): Calcula o valor máximo dos valores em uma coluna.\n",
    "\n",
    "- sum(): Calcula a soma dos valores em uma coluna.\n",
    "\n",
    "- quantile(): Calcula um percentual específico dos valores em uma coluna (por exemplo, 25% para o primeiro quartil, 50% para a mediana e 75% para o terceiro quartil)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras funções algébricas\n",
    "\n",
    "- var(): Calcula a variância dos valores em uma coluna (a média dos quadrados das diferenças entre cada valor e a média dividida pelo número de valores).\n",
    " \n",
    "- skew(): Calcula o coeficiente de assimetria dos valores em uma coluna (a média dos quadrados das diferenças entre cada valor e a média dividida pelo desvio padrão elevado ao quadrado).\n",
    " \n",
    "- kurt(): Calcula o coeficiente de curtose dos valores em uma coluna (a média dos quadrados das diferenças entre cada valor e a média dividida pelo desvio padrão elevado ao quadrado elevado a quatro).\n",
    " \n",
    "- cumsum(): Calcula a soma acumulada dos valores em uma coluna (a soma dos valores anteriores até o valor atual).\n",
    " \n",
    "- cumprod(): Calcula o produto acumulado dos valores em uma coluna (o produto dos valores anteriores até o valor atual).\n",
    " \n",
    "- cummin(): Calcula o valor mínimo acumulado dos valores em uma coluna (o valor mínimo dos valores anteriores até o valor atual).\n",
    " \n",
    "- cummax(): Calcula o valor máximo acumulado dos valores em uma coluna (o valor máximo dos valores anteriores até o valor atual).\n",
    " \n",
    "- cumvar(): Calcula a variância acumulada dos valores em uma coluna (a variância dos valores anteriores até o valor atual)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de Dados\n",
    "\n",
    "A limpeza de dados é uma parte crítica da análise de dados. Pandas oferece várias funções para facilitar este processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dacio.souza\\AppData\\Local\\Temp\\ipykernel_17092\\3014837484.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"Duration\"].loc[7] = 45\n",
      "C:\\Users\\dacio.souza\\AppData\\Local\\Temp\\ipykernel_17092\\3014837484.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Duration\"].loc[7] = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Date</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/01'</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>409.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/02'</td>\n",
       "      <td>117</td>\n",
       "      <td>145</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/03'</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/04'</td>\n",
       "      <td>109</td>\n",
       "      <td>175</td>\n",
       "      <td>282.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/05'</td>\n",
       "      <td>117</td>\n",
       "      <td>148</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/06'</td>\n",
       "      <td>102</td>\n",
       "      <td>127</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/07'</td>\n",
       "      <td>110</td>\n",
       "      <td>136</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/08'</td>\n",
       "      <td>104</td>\n",
       "      <td>134</td>\n",
       "      <td>253.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>'2020/12/09'</td>\n",
       "      <td>109</td>\n",
       "      <td>133</td>\n",
       "      <td>195.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/10'</td>\n",
       "      <td>98</td>\n",
       "      <td>124</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/11'</td>\n",
       "      <td>103</td>\n",
       "      <td>147</td>\n",
       "      <td>329.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/12'</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>250.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/12'</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>250.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/13'</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>345.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/14'</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>379.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/15'</td>\n",
       "      <td>98</td>\n",
       "      <td>123</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/16'</td>\n",
       "      <td>98</td>\n",
       "      <td>120</td>\n",
       "      <td>215.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/17'</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/18'</td>\n",
       "      <td>90</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/19'</td>\n",
       "      <td>103</td>\n",
       "      <td>123</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/20'</td>\n",
       "      <td>97</td>\n",
       "      <td>125</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/21'</td>\n",
       "      <td>108</td>\n",
       "      <td>131</td>\n",
       "      <td>364.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>119</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/23'</td>\n",
       "      <td>130</td>\n",
       "      <td>101</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45</td>\n",
       "      <td>'2020/12/24'</td>\n",
       "      <td>105</td>\n",
       "      <td>132</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/25'</td>\n",
       "      <td>102</td>\n",
       "      <td>126</td>\n",
       "      <td>334.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>20201226</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/27'</td>\n",
       "      <td>92</td>\n",
       "      <td>118</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/28'</td>\n",
       "      <td>103</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/29'</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/30'</td>\n",
       "      <td>102</td>\n",
       "      <td>129</td>\n",
       "      <td>380.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>'2020/12/31'</td>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration          Date  Pulse  Maxpulse  Calories\n",
       "0         60  '2020/12/01'    110       130     409.1\n",
       "1         60  '2020/12/02'    117       145     479.0\n",
       "2         60  '2020/12/03'    103       135     340.0\n",
       "3         45  '2020/12/04'    109       175     282.4\n",
       "4         45  '2020/12/05'    117       148     406.0\n",
       "5         60  '2020/12/06'    102       127     300.0\n",
       "6         60  '2020/12/07'    110       136     374.0\n",
       "7         45  '2020/12/08'    104       134     253.3\n",
       "8         30  '2020/12/09'    109       133     195.1\n",
       "9         60  '2020/12/10'     98       124     269.0\n",
       "10        60  '2020/12/11'    103       147     329.3\n",
       "11        60  '2020/12/12'    100       120     250.7\n",
       "12        60  '2020/12/12'    100       120     250.7\n",
       "13        60  '2020/12/13'    106       128     345.3\n",
       "14        60  '2020/12/14'    104       132     379.3\n",
       "15        60  '2020/12/15'     98       123     275.0\n",
       "16        60  '2020/12/16'     98       120     215.2\n",
       "17        60  '2020/12/17'    100       120     300.0\n",
       "18        45  '2020/12/18'     90       112       NaN\n",
       "19        60  '2020/12/19'    103       123     323.0\n",
       "20        45  '2020/12/20'     97       125     243.0\n",
       "21        60  '2020/12/21'    108       131     364.2\n",
       "22        45           NaN    100       119     282.0\n",
       "23        60  '2020/12/23'    130       101     300.0\n",
       "24        45  '2020/12/24'    105       132     246.0\n",
       "25        60  '2020/12/25'    102       126     334.5\n",
       "26        60      20201226    100       120     250.0\n",
       "27        60  '2020/12/27'     92       118     241.0\n",
       "28        60  '2020/12/28'    103       132       NaN\n",
       "29        60  '2020/12/29'    100       132     280.0\n",
       "30        60  '2020/12/30'    102       129     380.3\n",
       "31        60  '2020/12/31'     92       115     243.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "# print(df)\n",
    "# Removendo linhas com valores ausentes\n",
    "df_limpo = df.dropna(subset=['Calories'])\n",
    "\n",
    "\n",
    "# Preenchendo valores ausentes com zero\n",
    "df_preenchido = df.fillna(df['Calories'].mean())\n",
    "\n",
    "# Removendo duplicatas\n",
    "df_unico = df.drop_duplicates()\n",
    "\n",
    "df_limpo, df_preenchido, df_unico\n",
    "df[\"Duration\"].loc[7] = 45\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "    Duration          Date  Pulse  Maxpulse  Calories\n",
      "0         60  '2020/12/01'    110       130     409.1\n",
      "1         60  '2020/12/02'    117       145     479.0\n",
      "2         60  '2020/12/03'    103       135     340.0\n",
      "3         45  '2020/12/04'    109       175     282.4\n",
      "4         45  '2020/12/05'    117       148     406.0\n",
      "5         60  '2020/12/06'    102       127     300.0\n",
      "6         60  '2020/12/07'    110       136     374.0\n",
      "7        450  '2020/12/08'    104       134     253.3\n",
      "8         30  '2020/12/09'    109       133     195.1\n",
      "9         60  '2020/12/10'     98       124     269.0\n",
      "10        60  '2020/12/11'    103       147     329.3\n",
      "11        60  '2020/12/12'    100       120     250.7\n",
      "12        60  '2020/12/12'    100       120     250.7\n",
      "13        60  '2020/12/13'    106       128     345.3\n",
      "14        60  '2020/12/14'    104       132     379.3\n",
      "15        60  '2020/12/15'     98       123     275.0\n",
      "16        60  '2020/12/16'     98       120     215.2\n",
      "17        60  '2020/12/17'    100       120     300.0\n",
      "18        45  '2020/12/18'     90       112       NaN\n",
      "19        60  '2020/12/19'    103       123     323.0\n",
      "20        45  '2020/12/20'     97       125     243.0\n",
      "21        60  '2020/12/21'    108       131     364.2\n",
      "22        45           NaN    100       119     282.0\n",
      "23        60  '2020/12/23'    130       101     300.0\n",
      "24        45  '2020/12/24'    105       132     246.0\n",
      "25        60  '2020/12/25'    102       126     334.5\n",
      "26        60      20201226    100       120     250.0\n",
      "27        60  '2020/12/27'     92       118     241.0\n",
      "28        60  '2020/12/28'    103       132       NaN\n",
      "29        60  '2020/12/29'    100       132     280.0\n",
      "30        60  '2020/12/30'    102       129     380.3\n",
      "31        60  '2020/12/31'     92       115     243.0\n",
      "    Duration          Date  Pulse  Maxpulse  Calories\n",
      "0         60  '2020/12/01'    110       130     409.1\n",
      "1         60  '2020/12/02'    117       145     479.0\n",
      "2         60  '2020/12/03'    103       135     340.0\n",
      "3         45  '2020/12/04'    109       175     282.4\n",
      "4         45  '2020/12/05'    117       148     406.0\n",
      "5         60  '2020/12/06'    102       127     300.0\n",
      "6         60  '2020/12/07'    110       136     374.0\n",
      "7        450  '2020/12/08'    104       134     253.3\n",
      "8         30  '2020/12/09'    109       133     195.1\n",
      "9         60  '2020/12/10'     98       124     269.0\n",
      "10        60  '2020/12/11'    103       147     329.3\n",
      "11        60  '2020/12/12'    100       120     250.7\n",
      "12        60  '2020/12/12'    100       120     250.7\n",
      "13        60  '2020/12/13'    106       128     345.3\n",
      "14        60  '2020/12/14'    104       132     379.3\n",
      "15        60  '2020/12/15'     98       123     275.0\n",
      "16        60  '2020/12/16'     98       120     215.2\n",
      "17        60  '2020/12/17'    100       120     300.0\n",
      "18        45  '2020/12/18'     90       112       NaN\n",
      "19        60  '2020/12/19'    103       123     323.0\n",
      "20        45  '2020/12/20'     97       125     243.0\n",
      "21        60  '2020/12/21'    108       131     364.2\n",
      "22        45           NaN    100       119     282.0\n",
      "23        60  '2020/12/23'    130       101     300.0\n",
      "24        45  '2020/12/24'    105       132     246.0\n",
      "25        60  '2020/12/25'    102       126     334.5\n",
      "26        60      20201226    100       120     250.0\n",
      "27        60  '2020/12/27'     92       118     241.0\n",
      "28        60  '2020/12/28'    103       132       NaN\n",
      "29        60  '2020/12/29'    100       132     280.0\n",
      "30        60  '2020/12/30'    102       129     380.3\n",
      "31        60  '2020/12/31'     92       115     243.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.options.display.max_rows) \n",
    "# print(df)\n",
    "# pd.options.display.max_rows = 500\n",
    "# print(df)\n",
    "pd.options.display.max_rows = 50\n",
    "print(df)\n",
    "print(df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para exibir todo DataFrame\n",
    "print(df.to_string()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura de Dados de Diferentes Fontes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos CSV\n",
    " Arquivos CSV (Valores Separados por Vírgula) são uma das formas mais comuns de armazenamento de dados tabulares. \n",
    " \n",
    " Utilizar a biblioteca Pandas para ler, escrever e manipular dados em arquivos CSV de maneira eficiente, aproveitando as funcionalidades avancadas para analise de dados.\n",
    " \n",
    " Função pd.read_csv() para carregar dados de um arquivo CSV diretamente para um DataFrame, permitindo uma manipulação fácil e flexível dos dados.\n",
    "\n",
    " - Parâmetros úteis como sep para delimitadores customizados e usecols para selecionar colunas específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando dados de um arquivo CSV\n",
    "df_csv = pd.read_csv('dadosFictícios/Exemplo_Aula_8.csv')\n",
    "df_csv.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "\n",
    "# df = pd.read_json('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.json')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Exemplo: Leitura de um arquivo CSV com Pandas\n",
    "df = pd.read_csv('dados/usuarios.csv')\n",
    "print(df.head())  # Mostra as primeiras 5 linhas do DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrita para CSV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.to_csv('dados/saida_pandas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar um DataFrame para um arquivo CSV usando o método to_csv(), permitindo salvar os resultados de análises e manipulações dos dados.\n",
    "\n",
    "- Argumento index=False para evitar a escrita do índice como uma coluna no arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Escrita de um DataFrame em um arquivo CSV\n",
    "df_novo = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Carol'],\n",
    "    'Idade': [25, 30, 22],\n",
    "    'Email': ['alice@example.com', 'bob@example.com', 'carol@example.com']\n",
    "})\n",
    "\n",
    "df_novo.to_csv('saida_pandas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tarefas de dados:\n",
    "Utilizar um arquivo CSV de sua escolha (pode ser um conjunto de dados público sobre um tema de interesse) para realizar as seguintes tarefas com Pandas:\n",
    "1. Carregar os dados em um DataFrame.\n",
    "2. Realizar uma análise exploratória básica (número de linhas, colunas, tipos de dados).\n",
    "3. Limpar os dados se necessário (tratar valores ausentes, remover duplicatas).\n",
    "4. Criar novas colunas com dados derivados ou calculados.\n",
    "5. Salvar o DataFrame modificado em um novo arquivo CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Duration  32 non-null     int64  \n",
      " 1   Date      31 non-null     object \n",
      " 2   Pulse     32 non-null     int64  \n",
      " 3   Maxpulse  32 non-null     int64  \n",
      " 4   Calories  30 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "df.head(3)\n",
    "df.tail()\n",
    "df.info()\n",
    "df.describe()\n",
    "df['TotalCalories'] = df['Calories'].cumsum()\n",
    "df['Potencia'] = df['Calories'] / df['Duration']\n",
    "df.to_csv('dados/novoteste.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulacao de Dados JSON com Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo:\n",
    "Utilizar a biblioteca Pandas para manipular dados no formato JSON, convertendo-os facilmente entre formatos JSON e DataFrame para analise e processamento de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função pd.read_json() para carregar dados JSON em um DataFrame, discutindo diferentes opções de orientação de dados (como records, split, index, etc.) e como elas afetam a leitura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nome  idade              email\n",
      "0  Alice     25  alice@example.com\n",
      "1    Bob     30    bob@example.com\n",
      "2  Carol     22  carol@example.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dacio.souza\\AppData\\Local\\Temp\\ipykernel_10620\\1526370021.py:5: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(dados_json)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemplo: Carregando dados JSON em um DataFrame\n",
    "dados_json = '{\"nome\": [\"Alice\", \"Bob\", \"Carol\"], \"idade\": [25, 30, 22], \"email\": [\"alice@example.com\", \"bob@example.com\", \"carol@example.com\"]}'\n",
    "df = pd.read_json(dados_json)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar a função pd.read_json() para carregar dados JSON em um DataFrame, discutindo diferentes opções de orientação de dados (como records, split, index, etc.) e como elas afetam a leitura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nome  idade\n",
      "0      João     30\n",
      "1       Ana     25\n",
      "2     Maria     35\n",
      "3     Pedro     40\n",
      "4      José     20\n",
      "5    Marcos     30\n",
      "6    Carlos     35\n",
      "7     Jorge     40\n",
      "8   Mariana     20\n",
      "9     Marta     25\n",
      "10    Joana     25\n",
      "11    Carla     35\n",
      "12    Jorge     40\n",
      "13  Mariana     20\n",
      "14    Marta     25\n"
     ]
    }
   ],
   "source": [
    "# Carregando JSON com orientação diferente\n",
    "df_orientado = pd.read_json('dados/saidaPessoas.json', orient='records')\n",
    "# print(df_orientado)\n",
    "\n",
    "# df_orientado.to_json('dados/saida_orientada.json', orient='table')\n",
    "normalizado = pd.json_normalize(df_orientado['empregados'])\n",
    "print(normalizado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"schema\":{\n",
      "        \"fields\":[\n",
      "            {\n",
      "                \"name\":\"index\",\n",
      "                \"type\":\"integer\"\n",
      "            },\n",
      "            {\n",
      "                \"name\":\"Produto\",\n",
      "                \"type\":\"string\"\n",
      "            },\n",
      "            {\n",
      "                \"name\":\"Preco\",\n",
      "                \"type\":\"number\"\n",
      "            },\n",
      "            {\n",
      "                \"name\":\"Quantidade\",\n",
      "                \"type\":\"integer\"\n",
      "            }\n",
      "        ],\n",
      "        \"primaryKey\":[\n",
      "            \"index\"\n",
      "        ],\n",
      "        \"pandas_version\":\"1.4.0\"\n",
      "    },\n",
      "    \"data\":[\n",
      "        {\n",
      "            \"index\":0,\n",
      "            \"Produto\":\"Mesa\",\n",
      "            \"Preco\":300.0,\n",
      "            \"Quantidade\":10\n",
      "        },\n",
      "        {\n",
      "            \"index\":1,\n",
      "            \"Produto\":\"Cadeira\",\n",
      "            \"Preco\":150.0,\n",
      "            \"Quantidade\":20\n",
      "        },\n",
      "        {\n",
      "            \"index\":2,\n",
      "            \"Produto\":\"Lampada\",\n",
      "            \"Preco\":50.0,\n",
      "            \"Quantidade\":30\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Exemplo: Convertendo um DataFrame em JSON\n",
    "df_novo = pd.DataFrame({\n",
    "    'Produto': ['Mesa', 'Cadeira', 'Lampada'],\n",
    "    'Preco': [300.00, 150.00, 50.00],\n",
    "    'Quantidade': [10, 20, 30]\n",
    "})\n",
    "\n",
    "json_saida = df_novo.to_json(orient='table', indent=4)\n",
    "print(json_saida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização de dados JSON aninhados usando pd.json_normalize, facilitando a análise de dados complexos e hierárquicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nome  info.idade     info.cidade\n",
      "0  João          30       São Paulo\n",
      "1   Ana          25  Rio de Janeiro\n"
     ]
    }
   ],
   "source": [
    "dados_aninhados = [\n",
    "    {'nome': 'João', 'info': {'idade': 30, 'cidade': 'São Paulo'}},\n",
    "    {'nome': 'Ana', 'info': {'idade': 25, 'cidade': 'Rio de Janeiro'}}\n",
    "]\n",
    "\n",
    "df_normalizado = pd.json_normalize(dados_aninhados)\n",
    "print(df_normalizado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise com Pandas: Convertendo dados JSON em DataFrame para análise mais profunda usando Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Simulando dados JSON\n",
    "dados_json = '''\n",
    "[\n",
    "    {\"nome\": \"Alice\", \"idade\": 30, \"cidade\": \"New York\"},\n",
    "    {\"nome\": \"Bob\", \"idade\": 25, \"cidade\": \"Los Angeles\"}\n",
    "]\n",
    "'''\n",
    "dados = json.loads(dados_json)\n",
    "df = pd.DataFrame(dados)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio:\n",
    "Dado um DataFrame contendo informações sobre filmes (titulo, gênero, ano de lançamento), converta-o para o formato JSON. Em seguida, carregue esse JSON de volta para um DataFrame e adicione uma nova coluna com a duração dos filmes. Salve o DataFrame final como um novo arquivo JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos Excel:\n",
    "\n",
    "### Objetivo:\n",
    "Usar a biblioteca Pandas para a manipulacao de dados provenientes de arquivos Excel, abrangendo desde a leitura de multiplas planilhas ate a escrita de dados em novos arquivos Excel.\n",
    "\n",
    "Pandas pode facilmente ler planilhas do Excel usando o método pd.read_excel(), tornando a transição de dados do Excel para análise em Python suave.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Carregando dados de um arquivo Excel\n",
    "df_excel = pd.read_excel('dadosFictícios/Exemplo_Aula_10.xlsx')\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar múltiplas planilhas de um único arquivo Excel em diferentes DataFrames, utilizando o argumento sheet_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile('dados/exemplo.xlsx')\n",
    "df_sheet1 = pd.read_excel(xlsx, 'Planilha1')\n",
    "df_sheet2 = pd.read_excel(xlsx, 'Planilha2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrevendo dados em um arquivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo: Escrevendo dados em um arquivo Excel\n",
    "df_novo = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Carol'],\n",
    "    'Idade': [25, 30, 22],\n",
    "    'Email': ['alice@example.com', 'bob@example.com', 'carol@example.com']\n",
    "})\n",
    "\n",
    "with pd.ExcelWriter('dados/saida.xlsx') as writer:\n",
    "    df_novo.to_excel(writer, sheet_name='NovaPlanilha', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar um DataFrame em um arquivo Excel, usando o método to_excel(), e como escrever múltiplos DataFrames em diferentes planilhas do mesmo arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('dados/saida.xlsx') as writer:\n",
    "    df_sheet1.to_excel(writer, sheet_name='NovaPlanilha1', index=False)\n",
    "    df_sheet2.to_excel(writer, sheet_name='NovaPlanilha2', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinação de múltiplos DataFrames e a utilização de funções como merge e concat para integrar dados de várias fontes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando dados de duas planilhas\n",
    "df_concatenado = pd.concat([df_sheet1, df_sheet2], ignore_index=True)\n",
    "print(df_concatenado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinando Dados de Multiplos Arquivos Excel com Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objetivo:\n",
    "Combinar dados de multiplas fontes, especificamente de varios arquivos Excel, em um unico DataFrame usando Pandas, para analise consolidada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando dados de multiplos arquivos Excel\n",
    "df1 = pd.read_excel('dados_janeiro.xlsx')\n",
    "df2 = pd.read_excel('dados_fevereiro.xlsx')\n",
    "\n",
    "# Combinando os DataFrames\n",
    "df_combinado = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_combinado.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo: Combinando dados usando merge\n",
    "df_clientes = pd.read_excel('clientes.xlsx')\n",
    "df_vendas = pd.read_excel('vendas.xlsx')\n",
    "\n",
    "df_final = pd.merge(df_vendas, df_clientes, on='cliente_id')\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio:\n",
    "Imagine que você tenha dois arquivos Excel, cada um contendo dados de vendas de diferentes meses. Seu desafio é carregar ambos os arquivos em DataFrames, combinar os dados em um único DataFrame e calcular o total de vendas para cada produto. Finalmente, escreva o resultado em um novo arquivo Excel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio:\n",
    "Você possui três arquivos Excel com dados de vendas dos primeiros três trimestres do ano. Cada arquivo contém dados de vendas com as colunas 'Data', 'Produto' e 'Quantidade'. Seu desafio é carregar esses arquivos em DataFrames separados, combiná-los em um único DataFrame e, em seguida, calcular o total de vendas por produto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights para Dados\n",
    "Os dados muitas vezes estão espalhados por vários arquivos ou planilhas e a habilidade de combiná-los é crucial para análises abrangentes.\n",
    "\n",
    "Cenário comum onde dados de vendas estão distribuídos mensalmente em diferentes arquivos e precisam ser consolidados para análise anual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar múltiplos arquivos Excel, usando laços for junto com listas de nomes de arquivos ou padrões de correspondência de nomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Carregando todos os arquivos Excel no diretório atual\n",
    "arquivos_excel = glob.glob('dados_mes_*.xlsx')\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "for arquivo in arquivos_excel:\n",
    "    df = pd.read_excel(arquivo)\n",
    "    df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "\n",
    "print(df_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar pd.concat() para combinar DataFrames verticalmente (unindo dados) e pd.merge() para combinar horizontalmente (enriquecendo os dados com informações adicionais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo df_vendas e df_clientes como DataFrames previamente carregados\n",
    "df_combinado = pd.merge(df_vendas, df_clientes, on='cliente_id')\n",
    "print(df_combinado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar e tratar os dados após a combinação, como lidar com valores ausentes, duplicatas e inconsistências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores ausentes\n",
    "print(df_combinado.isnull().sum())\n",
    "\n",
    "# Removendo duplicatas\n",
    "df_combinado.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Db SQL\n",
    "Para dados armazenados em bancos de dados, Pandas pode executar consultas SQL diretamente e retornar o resultado como um DataFrame utilizando o método pd.read_sql_query()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sqlalchemy\n",
      "  Obtaining dependency information for sqlalchemy from https://files.pythonhosted.org/packages/dc/01/bff536f96ea323a7d80df128a7bc947e3c25a60383425bf491232112c30d/SQLAlchemy-2.0.30-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n",
      "  Obtaining dependency information for typing-extensions>=4.6.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/53/80/3d94d5999b4179d91bcc93745d1b0815b073d61be79dd546b840d17adb18/greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Downloading SQLAlchemy-2.0.30-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.6/2.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "   ---------------------------------------- 0.0/293.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  286.7/293.6 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 293.6/293.6 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: typing-extensions, greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.0.3 sqlalchemy-2.0.30 typing-extensions-4.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Criando uma conexão ao banco de dados (exemplo SQLite)\n",
    "engine = create_engine('sqlite:///banco_de_dados.db')\n",
    "df\n",
    "df.to_sql('tabedfhgdhgla', engine, if_exists='append', index=False)\n",
    "# Carregando dados via consulta SQL\n",
    "# df_sql = pd.read_sql_query(\"SELECT * FROM sua_tabela\", engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza e Preparação de Dados\n",
    "- Uma etapa fundamental no processo de análise de dados é a limpeza e preparação dos dados. \n",
    "- Esta fase envolve tratar valores ausentes, remover duplicatas, filtrar dados, e fazer transformações necessárias para garantir que os dados estejam em um formato adequado para análise. Vamos explorar técnicas comuns de limpeza de dados usando Pandas.\n",
    "\n",
    "- Coisas que podem ter de erradas nos datasets\n",
    "  - celulas vazias\n",
    "  - valores duplicados\n",
    "  - valores fora do formato\n",
    "  - valores fora do contexto\n",
    "  - valores inconsistentes\n",
    "  - valores que não fazem sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de Valores Ausentes\n",
    "- Valores ausentes são comuns em muitos conjuntos de dados e podem ser o resultado de erros de entrada de dados, falhas na coleta de dados, ou outras inconsistências. \n",
    "- Pandas oferece várias formas de lidar com valores ausentes:\n",
    "\n",
    "  - Descartando valores ausentes: Usar dropna() para remover linhas ou colunas que contêm valores ausentes.\n",
    "    - É útil e ok, se estiver lidando com dataset grande, mas pode perder informações importantes, o que impacta especialmente em datasets pequenos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "# Removendo linhas com valores ausentes\n",
    "df_limpo = df.dropna()\n",
    "print(df_limpo)\n",
    "# Removendo colunas com valores ausentes\n",
    "df_limpo = df.dropna(axis=1)\n",
    "\n",
    "df_limpo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__dropna()__: Retorna um DataFrame já com a remoção de linhas com valores ausentes.\n",
    "\n",
    "__dropna(axis=1)__: Retorna um DataFrame já com a remoção de colunas com valores ausentes.\n",
    "\n",
    "Para que o método dropna() ao invés de retornar um novo DataFrame, modifique o DataFrame original, use o argumento `inplace=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __fillna()__ \n",
    "Preenchendo valores ausentes: Utilizar fillna() para substituir os valores ausentes por um valor específico, como a média da coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "\n",
    "# Preenchendo valores ausentes com a média da coluna\n",
    "df.fillna(999999, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "\n",
    "# Preenchendo valores ausentes com a média da coluna\n",
    "df['Calories'] = df['Calories'].fillna(df['Calories'].mean())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remoção de Duplicatas: Dados duplicados podem distorcer análises e resultados. Pandas torna fácil identificar e remover duplicatas com drop_duplicates().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicatas\n",
    "df_unico = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtragem de Dados\n",
    "Filtrar dados é um processo chave para focar em informações relevantes. Com Pandas, você pode usar condições booleanas para filtrar linhas que atendem a critérios específicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dadosFictícios\\Exemplo_Aula_6.csv')\n",
    "print(df)\n",
    "\n",
    "# Filtrando dados onde a coluna 'idade' é maior que 40\n",
    "df_filtrado = df[df['Idade'] > 40]\n",
    "df_filtrado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erro de formato\n",
    "\n",
    "- Células com dados no formato errado podem causar problemas em análises e visualizações. \n",
    "- Nestes casos 2 soluções são mais práticadas:\n",
    "  - Remover as linhas com valores fora do formato, usando dropna().\n",
    "  - Converter todas as células da coluna para um mesmo formato, com astype() e to_datetime(), por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo: As linhas 22 e 26 contêm valores fora do formato esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "print(df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/2024\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, time\n",
    "\n",
    "data_e_hora_atuais = datetime.now()\n",
    "data_e_hora_em_texto = data_e_hora_atuais.strftime('%d/%m/%Y')\n",
    "\n",
    "print(data_e_hora_em_texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = '{}/{}/{}'.format(data_atual.day, data_atual.month,data_atual.year)\n",
    "\n",
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "\n",
    "df['novaData'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "# df['novaData'] = df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "# df['novaData'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['novaData'] = df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "df.dropna(subset=['novaData'], inplace=True)\n",
    "\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformação de Dados\n",
    "  - Transformações são frequentemente necessárias para adequar os dados às necessidades da análise. Isso pode incluir a criação de novas colunas a partir de dados existentes, conversão de tipos de dados, entre outros.\n",
    "\n",
    "- Adicionando novas colunas: Você pode adicionar colunas baseadas em operações com colunas existentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criando uma nova coluna 'idade_dobrada'\n",
    "df['PulMax/Pulse'] = df['Maxpulse'] / df['Pulse']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversão de tipos de dados: Use astype() para converter o tipo de dados de uma coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertendo a coluna 'idade' para float\n",
    "df['modificado'] = (df['PulMax/Pulse']*10).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exemplo Prático: \n",
    "Considerando um DataFrame df_vendas que contém dados de vendas, incluindo algumas colunas com valores ausentes e possíveis duplicatas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo valores ausentes na coluna 'quantidade' com a média\n",
    "df_vendas['quantidade'] = df_vendas['quantidade'].fillna(df_vendas['quantidade'].mean())\n",
    "\n",
    "# Removendo duplicatas\n",
    "df_vendas = df_vendas.drop_duplicates()\n",
    "\n",
    "# Filtrando vendas com valor maior que 500\n",
    "df_vendas_altas = df_vendas[df_vendas['valor'] > 500]\n",
    "\n",
    "# Adicionando uma nova coluna 'valor_total' (quantidade * valor)\n",
    "df_vendas['valor_total'] = df_vendas['quantidade'] * df_vendas['valor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando e lidando com dados \"Errados\" ou \"Inconsistentes\"\n",
    "\n",
    "Um dataset pode conter um dado errado que não necessáriamente esteja vazio ou no formato errado. Por exemplo, um valor de idade negativo, ou um valor de data de nascimento no futuro, ou um valor digitado 199 onde se esperaria 1.99, ou um valor de temperatura de -300 graus Celsius, ou um valor de peso de 2 toneladas para um bebê recém-nascido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando para o dataset, você pode identificar esses dados errados e decidir como lidar com eles. Você pode corrigir manualmente, remover, ou substituir por um valor correto.\n",
    "Vejao exemplo da linha 7 do dataset abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há nada de errado com a duração do exercício ser de 450, mas isso parece ser inconsistente com os valores das outras linhas da coluna e com a quantidade de calorias queimadas. Isso pode ser um erro de digitação, e você pode decidir corrigir manualmente ou remover a linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[7, 'Duration'] = 45\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso temos um dataset relativamente pequeno e é possível corrigir manualmente. Mas em datasets maiores, você pode usar regras de negócio ou algoritmos para identificar e corrigir esses dados inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "#exemplo de alteração de valores\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.loc[x, \"Duration\"] = 120\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "#exemplo de remoção de valores\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.drop(x, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicatas\n",
    "\n",
    "Valores duplicados podem distorcer análises e resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "print(df.duplicated().to_string())\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlações\n",
    "\n",
    "O método corr() calcula a correlação entre cada uma das colunas do DataFrame. \n",
    "\n",
    "A correlação é uma medida estatística que descreve a relação entre duas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Duration       Date  Pulse  Maxpulse  Calories\n",
      "0         60 2020-12-01    110       130     409.1\n",
      "1         60 2020-12-02    117       145     479.0\n",
      "2         60 2020-12-03    103       135     340.0\n",
      "3         45 2020-12-04    109       175     282.4\n",
      "4         45 2020-12-05    117       148     406.0\n",
      "5         60 2020-12-06    102       127     300.0\n",
      "6         60 2020-12-07    110       136     374.0\n",
      "7        120 2020-12-08    104       134     253.3\n",
      "8         30 2020-12-09    109       133     195.1\n",
      "9         60 2020-12-10     98       124     269.0\n",
      "10        60 2020-12-11    103       147     329.3\n",
      "11        60 2020-12-12    100       120     250.7\n",
      "13        60 2020-12-13    106       128     345.3\n",
      "14        60 2020-12-14    104       132     379.3\n",
      "15        60 2020-12-15     98       123     275.0\n",
      "16        60 2020-12-16     98       120     215.2\n",
      "17        60 2020-12-17    100       120     300.0\n",
      "19        60 2020-12-19    103       123     323.0\n",
      "20        45 2020-12-20     97       125     243.0\n",
      "21        60 2020-12-21    108       131     364.2\n",
      "23        60 2020-12-23    130       101     300.0\n",
      "24        45 2020-12-24    105       132     246.0\n",
      "25        60 2020-12-25    102       126     334.5\n",
      "26        60 2020-12-26    100       120     250.0\n",
      "27        60 2020-12-27     92       118     241.0\n",
      "29        60 2020-12-29    100       132     280.0\n",
      "30        60 2020-12-30    102       129     380.3\n",
      "31        60 2020-12-31     92       115     243.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Date</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036126</td>\n",
       "      <td>-0.107417</td>\n",
       "      <td>-0.150758</td>\n",
       "      <td>0.035323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>-0.036126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.380088</td>\n",
       "      <td>-0.549973</td>\n",
       "      <td>-0.368101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td>-0.107417</td>\n",
       "      <td>-0.380088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200177</td>\n",
       "      <td>0.503243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxpulse</th>\n",
       "      <td>-0.150758</td>\n",
       "      <td>-0.549973</td>\n",
       "      <td>0.200177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calories</th>\n",
       "      <td>0.035323</td>\n",
       "      <td>-0.368101</td>\n",
       "      <td>0.503243</td>\n",
       "      <td>0.338515</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Duration      Date     Pulse  Maxpulse  Calories\n",
       "Duration  1.000000 -0.036126 -0.107417 -0.150758  0.035323\n",
       "Date     -0.036126  1.000000 -0.380088 -0.549973 -0.368101\n",
       "Pulse    -0.107417 -0.380088  1.000000  0.200177  0.503243\n",
       "Maxpulse -0.150758 -0.549973  0.200177  1.000000  0.338515\n",
       "Calories  0.035323 -0.368101  0.503243  0.338515  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dados/dataSujo.csv')\n",
    "\n",
    "df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.loc[x, \"Duration\"] = 120\n",
    "\n",
    "print(df.to_string())\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169 entries, 0 to 168\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Duration  169 non-null    int64  \n",
      " 1   Pulse     169 non-null    int64  \n",
      " 2   Maxpulse  169 non-null    int64  \n",
      " 3   Calories  164 non-null    float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 5.4 KB\n",
      "None          Duration       Pulse    Maxpulse     Calories\n",
      "count  169.000000  169.000000  169.000000   164.000000\n",
      "mean    63.846154  107.461538  134.047337   375.790244\n",
      "std     42.299949   14.510259   16.450434   266.379919\n",
      "min     15.000000   80.000000  100.000000    50.300000\n",
      "25%     45.000000  100.000000  124.000000   250.925000\n",
      "50%     60.000000  105.000000  131.000000   318.600000\n",
      "75%     60.000000  111.000000  141.000000   387.600000\n",
      "max    300.000000  159.000000  184.000000  1860.400000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.251712</td>\n",
       "      <td>-0.086029</td>\n",
       "      <td>0.820359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td>-0.251712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784994</td>\n",
       "      <td>0.015301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxpulse</th>\n",
       "      <td>-0.086029</td>\n",
       "      <td>0.784994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calories</th>\n",
       "      <td>0.820359</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.195309</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Duration     Pulse  Maxpulse  Calories\n",
       "Duration  1.000000 -0.251712 -0.086029  0.820359\n",
       "Pulse    -0.251712  1.000000  0.784994  0.015301\n",
       "Maxpulse -0.086029  0.784994  1.000000  0.195309\n",
       "Calories  0.820359  0.015301  0.195309  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dados/dataSujo2.csv')\n",
    "print(df.info(), df.describe())\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.loc[x, \"Duration\"] = 120\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados de correlação\n",
    "\t\n",
    "- 1: Correlação positiva perfeita\n",
    "- 0.9: Correlação positiva muito forte\n",
    "- \\- 0.9: Correlação negativa muito forte\n",
    "- 0.2: Correlação fraca, ou seja uma informação não está associada à outra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exibição de dados\n",
    "\n",
    "O pandas possui o método plot() para criar diagramas de dispersão, histogramas, gráficos de linha, e muito mais.\n",
    "Também podemos utilizar o submódulo matplotlib.pyplot ou o módulo saeborn para criar gráficos mais complexos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.plot(kind = 'scatter', x = 'Duration', y = 'Calories', color = 'red', label = 'Calorias x Tempo', figsize = (10, 6), grid = True, title = 'Correlação entre Calorias e Tempo', fontsize = 12, legend = True, style = '--', linewidth = 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação de Dados\n",
    "\n",
    "Depois de limpar e preparar os dados, o próximo passo é transformá-los para facilitar análises futuras.\n",
    "Operações de manipulação de dados, incluindo operações com colunas, funções de mapeamento, agrupamento, e agregação, utilizando a biblioteca Pandas.\n",
    "\n",
    "\n",
    "- Operações com Colunas: \n",
    "Adicionar, remover e modificar colunas: Pandas permite a manipulação flexível de colunas em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma nova coluna\n",
    "df['nova_coluna'] = df['coluna_existente'] * 10\n",
    "\n",
    "# Removendo uma coluna\n",
    "df = df.drop('coluna_para_remover', axis=1)\n",
    "\n",
    "# Modificar valores de uma coluna (por exemplo, aplicando uma função lambda)\n",
    "df['coluna_existente'] = df['coluna_existente'].apply(lambda x: x * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de Mapeamento\n",
    "apply() e map(): Estas funções permitem aplicar uma função ao longo de um eixo do DataFrame ou a uma Series, respectivamente, facilitando a transformação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apply() para aplicar uma função a todas as linhas de uma coluna\n",
    "df['coluna'] = df['coluna'].apply(lambda x: x + 100)\n",
    "\n",
    "# Usando map() para substituir valores em uma Series\n",
    "df['categoria'] = df['categoria'].map({'A': 1, 'B': 2, 'C': 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupamento e Agregação\n",
    "groupby(): Esta função é usada para agrupar dados com base em uma ou mais colunas e aplicar uma função de agregação (como soma, média, etc.) ao grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando dados pela coluna 'categoria' e calculando a média das outras colunas\n",
    "df_agrupado = df.groupby('categoria').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções de agregação: Após agrupar os dados, você pode aplicar várias funções de agregação para resumir os dados agrupados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando várias estatísticas agregadas após o agrupamento\n",
    "df_agrupado = df.groupby('categoria').agg({'coluna_numerica': ['mean', 'min', 'max']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Prático\n",
    "\n",
    "Suponha que temos um DataFrame df_vendas contendo colunas para data, categoria, valor_venda e quantidade. Vamos realizar algumas transformações para analisar esses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulando o DataFrame\n",
    "data = {\n",
    "    'data': pd.date_range('2021-01-01', periods=4),\n",
    "    'categoria': ['A', 'B', 'A', 'B'],\n",
    "    'valor_venda': [100, 200, 150, 300],\n",
    "    'quantidade': [1, 2, 2, 3]\n",
    "}\n",
    "df_vendas = pd.DataFrame(data)\n",
    "\n",
    "# Adicionando uma coluna 'valor_total'\n",
    "df_vendas['valor_total'] = df_vendas['valor_venda'] * df_vendas['quantidade']\n",
    "\n",
    "# Agrupando por 'categoria' e calculando o valor total de vendas por categoria\n",
    "vendas_por_categoria = df_vendas.groupby('categoria')['valor_total'].sum()\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(vendas_por_categoria)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise e Visualização de Dados\n",
    "\n",
    "Pandas integra-se bem com Matplotlib e Seaborn para visualização de dados, permitindo a análise visual dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Histograma\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histograma\n",
    "df['Idade'].hist()\n",
    "plt.title('Distribuição de Idades')\n",
    "plt.xlabel('Idade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras\n",
    "sns.barplot(x='Cidade', y='Idade', data=df)\n",
    "plt.title('Média de Idade por Cidade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metodos = pd.read_excel('metodosPandas.xlsx', sheet_name='Sheet1')\n",
    "metodos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
