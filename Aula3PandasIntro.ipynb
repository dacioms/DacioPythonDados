{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Pandas e manipulação de arquivos com Pandas\n",
    "\n",
    "- Introdução ao Pandas\n",
    "    - Conceitos Básicos de Pandas\n",
    "      - Estruturas de dados: Series e DataFrames\n",
    "      - Criação de Series e DataFrames a partir de listas e dicionários\n",
    "      - Visualização de dados: cabeçalho, cauda e informações básicas\n",
    "- Manipulação de Dados com Pandas\n",
    "    - Carregamento de Dados\n",
    "      - Leitura de dados de diferentes fontes (CSV, Excel, SQL) \n",
    "      - Visualização inicial e sumário estatístico\n",
    "    - Limpeza e Preparação de Dados\n",
    "      - Tratamento de valores ausentes\n",
    "      - Remoção de duplicatas\n",
    "      - Filtragem de dados  \n",
    "    - Transformação de Dados\n",
    "      - Operações com colunas (adicionar, remover, modificar)\n",
    "      - Funções de mapeamento\n",
    "      - Agrupamento e agregação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "- Fornecer uma compreensão abrangente da biblioteca Pandas, uma ferramenta essencial no Python para análise de dados. Ao final do curso, você será capaz de manipular, limpar e explorar conjuntos de dados de forma eficiente. Estaremos cobrindo desde a configuração do ambiente de desenvolvimento até a realização de análises de dados complexas e visualização de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visão Geral do Pandas e sua Importância\n",
    "- Pandas é uma biblioteca de código aberto que fornece estruturas de dados de alto desempenho e ferramentas de análise de dados para a linguagem Python. \n",
    "- Com Pandas, você pode realizar tarefas essenciais de __pré-processamento__ e __análise de dados__, como a __limpeza de dados__, transformações, agregações, e muito mais. \n",
    "- A biblioteca é amplamente utilizada em diversas áreas, incluindo finanças, neurociência, economia, estatística, publicidade e web analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de Implementação Inicial com Pandas:\n",
    "- Vamos começar com um exemplo simples para demonstrar como iniciar com o Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criando um DataFrame simples\n",
    "data = {\n",
    "    'Nome': ['João', 'Ana', 'Pedro', 'Maria'],\n",
    "    'Idade': [28, 34, 29, 32],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# print(df, \"\\n\", \"_\"*50, \"\\n\")\n",
    "\n",
    "# Em notebooks o que é retornado da célula é renderizado (exibido) na saída da célula de código, não exigindo a função print\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria um DataFrame, que é uma das principais estruturas de dados do Pandas. \n",
    "\n",
    "Um DataFrame é semelhante a uma tabela de banco de dados ou uma planilha de Excel, com linhas e colunas. \n",
    "\n",
    "No exemplo acima, criamos um DataFrame a partir de um dicionário de listas, uma estrutura de dados muito comum em Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séries e DataFrames\n",
    "- Series: Uma Series é uma coluna unidimensional capaz de armazenar qualquer tipo de dados (inteiros, strings, floats, objetos Python, etc.). Cada elemento de uma Series é indexado, começando por padrão do índice 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    25.0\n",
      "1    30.0\n",
      "2    35.0\n",
      "3    40.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criando uma Series a partir de uma lista\n",
    "idades = pd.Series([25, 30, 35.0, 40])\n",
    "print(idades)\n",
    "# idades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrames: Um DataFrame é uma estrutura de dados bidimensional, como uma planilha ou uma tabela de banco de dados, com colunas de diferentes tipos. Pode ser visto como um conjunto de Series que compartilham o mesmo índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame a partir de um dicionário de listas\n",
    "data = {\n",
    "    'Nome': ['Ana', 'Bruno', 'Carlos', 'Diana','Fernando'],\n",
    "    'Idade': [28, 34, 29, 32, 45],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'Brasília']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Series e DataFrames\n",
    "- A partir de __listas__: Podemos criar uma Series diretamente de uma lista. Para criar um DataFrame a partir de listas, podemos combinar várias listas em um dicionário, onde cada chave se torna o nome da coluna.\n",
    "- A partir de __dicionários__: Um DataFrame também pode ser criado a partir de um dicionário de listas ou de Series, proporcionando uma forma intuitiva de especificar dados junto com seus rótulos de coluna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização de Dados\n",
    "- Pandas oferece métodos simples para uma rápida inspeção dos seus dados.\n",
    "- Ferramentas cruciais para uma primeira análise exploratória dos dados, permitindo uma visão geral rápida e eficiente da estrutura e conteúdo do seu conjunto de dados.\n",
    "\n",
    "Métodos <code>.head() e .tail()</code>: Use df.head(n) para visualizar as primeiras n linhas do DataFrame df, e df.tail(n) para as últimas n. Se n não for especificado, o padrão é 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Nome  Idade          Cidade\n",
      "0     Ana     28       São Paulo\n",
      "1   Bruno     34  Rio de Janeiro\n",
      "2  Carlos     29  Belo Horizonte\n",
      "********************************************************************************\n",
      "       Nome  Idade  Cidade\n",
      "10      Bob     30   Paris\n",
      "11  Charlie     35  London\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Nome': ['Ana', 'Bruno', 'Carlos', 'Diana','Fernando','João', 'Ana', 'Pedro', 'Maria', 'Alice', 'Bob', 'Charlie'],\n",
    "    'Idade': [28, 34, 29, 32, 45, 28, 34, 29, 32,25, 30, 35],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'Brasília','São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'New York', 'Paris', 'London']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head(3))  # Mostra as primeiras 5 linhas\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(df.tail(2)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Operações básicas de manipulação de dados com Pandas, como seleção de colunas, filtragem de linhas, e cálculos simples (médias, somas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Seleção de colunas\n",
    "print(df['Nome'])\n",
    "\n",
    "# Filtragem de linhas\n",
    "print(df[df['Idade'] > 18])\n",
    "\n",
    "# Cálculos simples\n",
    "print(df['Idade'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>.info()</code>: Este método fornece um resumo conciso do DataFrame, incluindo o número de entradas não-nulas em cada coluna, o tipo de dados e o uso de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>.describe()</code>: Oferece uma visão geral estatística das colunas numéricas, como contagem, média, desvio padrão, mínimos e máximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de Dados\n",
    "\n",
    "A limpeza de dados é uma parte crítica da análise de dados. Pandas oferece várias funções para facilitar este processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Removendo linhas com valores ausentes\n",
    "df_limpo = df.dropna()\n",
    "\n",
    "# Preenchendo valores ausentes com zero\n",
    "df_preenchido = df.fillna(0)\n",
    "\n",
    "# Removendo duplicatas\n",
    "df_unico = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura de Dados de Diferentes Fontes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos CSV\n",
    " Arquivos CSV (Valores Separados por Vírgula) são uma das formas mais comuns de armazenamento de dados tabulares. \n",
    " \n",
    " Utilizar a biblioteca Pandas para ler, escrever e manipular dados em arquivos CSV de maneira eficiente, aproveitando as funcionalidades avancadas para analise de dados.\n",
    " \n",
    " Função pd.read_csv() para carregar dados de um arquivo CSV diretamente para um DataFrame, permitindo uma manipulação fácil e flexível dos dados.\n",
    "\n",
    " - Parâmetros úteis como sep para delimitadores customizados e usecols para selecionar colunas específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Produto</th>\n",
       "      <th>Preço</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>235.76</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>295.82</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>235.59</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>171.80</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>168.39</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>285.38</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>449.83</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>477.65</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>343.30</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>338.66</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>413.46</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>300.01</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>120.15</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>379.64</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>496.96</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>206.91</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>371.64</td>\n",
       "      <td>17</td>\n",
       "      <td>2023-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>445.71</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>400.34</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>485.80</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>321.70</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>184.96</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>188.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>187.50</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sofá</td>\n",
       "      <td>327.83</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>280.84</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>488.09</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>372.22</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cadeira</td>\n",
       "      <td>134.12</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>122.57</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Produto   Preço  Quantidade        Data\n",
       "0      Mesa  235.76          18  2023-01-01\n",
       "1      Mesa  295.82           7  2023-01-02\n",
       "2      Mesa  235.59           8  2023-01-03\n",
       "3      Sofá  171.80          19  2023-01-04\n",
       "4      Sofá  168.39          12  2023-01-05\n",
       "5   Cadeira  285.38          18  2023-01-06\n",
       "6   Cadeira  449.83          10  2023-01-07\n",
       "7      Mesa  477.65          15  2023-01-08\n",
       "8      Mesa  343.30          10  2023-01-09\n",
       "9      Sofá  338.66          19  2023-01-10\n",
       "10  Cadeira  413.46           1  2023-01-11\n",
       "11  Cadeira  300.01          10  2023-01-12\n",
       "12     Sofá  120.15          12  2023-01-13\n",
       "13     Mesa  379.64          18  2023-01-14\n",
       "14  Cadeira  496.96          10  2023-01-15\n",
       "15  Cadeira  206.91           1  2023-01-16\n",
       "16  Cadeira  371.64          17  2023-01-17\n",
       "17  Cadeira  445.71          11  2023-01-18\n",
       "18  Cadeira  400.34           5  2023-01-19\n",
       "19     Sofá  485.80           4  2023-01-20\n",
       "20     Sofá  321.70           9  2023-01-21\n",
       "21     Sofá  184.96          15  2023-01-22\n",
       "22     Mesa  188.98           1  2023-01-23\n",
       "23  Cadeira  187.50           9  2023-01-24\n",
       "24     Sofá  327.83           8  2023-01-25\n",
       "25  Cadeira  280.84          14  2023-01-26\n",
       "26  Cadeira  488.09          18  2023-01-27\n",
       "27  Cadeira  372.22           1  2023-01-28\n",
       "28  Cadeira  134.12          12  2023-01-29\n",
       "29     Mesa  122.57           5  2023-01-30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando dados de um arquivo CSV\n",
    "df_csv = pd.read_csv('dadosFictícios/Exemplo_Aula_8.csv')\n",
    "# df_csv.info()\n",
    "df_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Exemplo: Leitura de um arquivo CSV com Pandas\n",
    "df = pd.read_csv('dados/usuarios.csv')\n",
    "print(df.head())  # Mostra as primeiras 5 linhas do DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrita para CSV:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.to_csv('dados/saida_pandas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar um DataFrame para um arquivo CSV usando o método to_csv(), permitindo salvar os resultados de análises e manipulações dos dados.\n",
    "\n",
    "- Argumento index=False para evitar a escrita do índice como uma coluna no arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Escrita de um DataFrame em um arquivo CSV\n",
    "df_novo = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Carol'],\n",
    "    'Idade': [25, 30, 22],\n",
    "    'Email': ['alice@example.com', 'bob@example.com', 'carol@example.com']\n",
    "})\n",
    "\n",
    "df_novo.to_csv('saida_pandas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tarefas de dados:\n",
    "Utilizar um arquivo CSV de sua escolha (pode ser um conjunto de dados público sobre um tema de interesse) para realizar as seguintes tarefas com Pandas:\n",
    "1. Carregar os dados em um DataFrame.\n",
    "2. Realizar uma análise exploratória básica (número de linhas, colunas, tipos de dados).\n",
    "3. Limpar os dados se necessário (tratar valores ausentes, remover duplicatas).\n",
    "4. Criar novas colunas com dados derivados ou calculados.\n",
    "5. Salvar o DataFrame modificado em um novo arquivo CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Solucao do Desafio (Exemplo com dados ficticios)\n",
    "# 1. Carregar os dados\n",
    "df = pd.read_csv('dados/usuarios.csv')\n",
    "# 2. Analise exploratoria basica\n",
    "print(df.info())\n",
    "\n",
    "# 3. Limpeza dos dados\n",
    "df.dropna(inplace=True)  # Remover linhas com valores ausentes\n",
    "df.drop_duplicates(inplace=True)  # Remover duplicatas\n",
    "\n",
    "# 4. Criar novas colunas\n",
    "df['Nova_Coluna'] = df['idade'] % 2\n",
    "\n",
    "print(df.head)\n",
    "# 5. Salvar em novo arquivo CSV\n",
    "df.to_csv('dados/exemplo_modificado.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulacao de Dados JSON com Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo:\n",
    "Utilizar a biblioteca Pandas para manipular dados no formato JSON, convertendo-os facilmente entre formatos JSON e DataFrame para analise e processamento de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função pd.read_json() para carregar dados JSON em um DataFrame, discutindo diferentes opções de orientação de dados (como records, split, index, etc.) e como elas afetam a leitura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemplo: Carregando dados JSON em um DataFrame\n",
    "dados_json = '{\"nome\": [\"Alice\", \"Bob\", \"Carol\"], \"idade\": [25, 30, 22], \"email\": [\"alice@example.com\", \"bob@example.com\", \"carol@example.com\"]}'\n",
    "df = pd.read_json(dados_json)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar a função pd.read_json() para carregar dados JSON em um DataFrame, discutindo diferentes opções de orientação de dados (como records, split, index, etc.) e como elas afetam a leitura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando JSON com orientação diferente\n",
    "df_orientado = pd.read_json('dados/saidaPessoas.json', orient='records')\n",
    "print(df_orientado)\n",
    "\n",
    "df_orientado.to_json('dados/saida_orientada.json', orient='records', indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Convertendo um DataFrame em JSON\n",
    "df_novo = pd.DataFrame({\n",
    "    'Produto': ['Mesa', 'Cadeira', 'Lampada'],\n",
    "    'Preco': [300.00, 150.00, 50.00],\n",
    "    'Quantidade': [10, 20, 30]\n",
    "})\n",
    "\n",
    "json_saida = df_novo.to_json(orient='records', indent=4)\n",
    "print(json_saida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização de dados JSON aninhados usando pd.json_normalize, facilitando a análise de dados complexos e hierárquicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_aninhados = [\n",
    "    {'nome': 'João', 'info': {'idade': 30, 'cidade': 'São Paulo'}},\n",
    "    {'nome': 'Ana', 'info': {'idade': 25, 'cidade': 'Rio de Janeiro'}}\n",
    "]\n",
    "\n",
    "df_normalizado = pd.json_normalize(dados_aninhados)\n",
    "print(df_normalizado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise com Pandas: Convertendo dados JSON em DataFrame para análise mais profunda usando Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Simulando dados JSON\n",
    "dados_json = '''\n",
    "[\n",
    "    {\"nome\": \"Alice\", \"idade\": 30, \"cidade\": \"New York\"},\n",
    "    {\"nome\": \"Bob\", \"idade\": 25, \"cidade\": \"Los Angeles\"}\n",
    "]\n",
    "'''\n",
    "dados = json.loads(dados_json)\n",
    "df = pd.DataFrame(dados)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio:\n",
    "Dado um DataFrame contendo informações sobre filmes (titulo, gênero, ano de lançamento), converta-o para o formato JSON. Em seguida, carregue esse JSON de volta para um DataFrame e adicione uma nova coluna com a duração dos filmes. Salve o DataFrame final como um novo arquivo JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos Excel:\n",
    "\n",
    "### Objetivo:\n",
    "Usar a biblioteca Pandas para a manipulacao de dados provenientes de arquivos Excel, abrangendo desde a leitura de multiplas planilhas ate a escrita de dados em novos arquivos Excel.\n",
    "\n",
    "Pandas pode facilmente ler planilhas do Excel usando o método pd.read_excel(), tornando a transição de dados do Excel para análise em Python suave.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Carregando dados de um arquivo Excel\n",
    "df_excel = pd.read_excel('dadosFictícios/Exemplo_Aula_10.xlsx')\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar múltiplas planilhas de um único arquivo Excel em diferentes DataFrames, utilizando o argumento sheet_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile('dados/exemplo.xlsx')\n",
    "df_sheet1 = pd.read_excel(xlsx, 'Planilha1')\n",
    "df_sheet2 = pd.read_excel(xlsx, 'Planilha2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrevendo dados em um arquivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo: Escrevendo dados em um arquivo Excel\n",
    "df_novo = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Carol'],\n",
    "    'Idade': [25, 30, 22],\n",
    "    'Email': ['alice@example.com', 'bob@example.com', 'carol@example.com']\n",
    "})\n",
    "\n",
    "with pd.ExcelWriter('dados/saida.xlsx') as writer:\n",
    "    df_novo.to_excel(writer, sheet_name='NovaPlanilha', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar um DataFrame em um arquivo Excel, usando o método to_excel(), e como escrever múltiplos DataFrames em diferentes planilhas do mesmo arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('dados/saida.xlsx') as writer:\n",
    "    df_sheet1.to_excel(writer, sheet_name='NovaPlanilha1', index=False)\n",
    "    df_sheet2.to_excel(writer, sheet_name='NovaPlanilha2', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinação de múltiplos DataFrames e a utilização de funções como merge e concat para integrar dados de várias fontes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando dados de duas planilhas\n",
    "df_concatenado = pd.concat([df_sheet1, df_sheet2], ignore_index=True)\n",
    "print(df_concatenado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinando Dados de Multiplos Arquivos Excel com Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objetivo:\n",
    "Combinar dados de multiplas fontes, especificamente de varios arquivos Excel, em um unico DataFrame usando Pandas, para analise consolidada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando dados de multiplos arquivos Excel\n",
    "df1 = pd.read_excel('dados_janeiro.xlsx')\n",
    "df2 = pd.read_excel('dados_fevereiro.xlsx')\n",
    "\n",
    "# Combinando os DataFrames\n",
    "df_combinado = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_combinado.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo: Combinando dados usando merge\n",
    "df_clientes = pd.read_excel('clientes.xlsx')\n",
    "df_vendas = pd.read_excel('vendas.xlsx')\n",
    "\n",
    "df_final = pd.merge(df_vendas, df_clientes, on='cliente_id')\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio:\n",
    "Imagine que você tenha dois arquivos Excel, cada um contendo dados de vendas de diferentes meses. Seu desafio é carregar ambos os arquivos em DataFrames, combinar os dados em um único DataFrame e calcular o total de vendas para cada produto. Finalmente, escreva o resultado em um novo arquivo Excel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio:\n",
    "Você possui três arquivos Excel com dados de vendas dos primeiros três trimestres do ano. Cada arquivo contém dados de vendas com as colunas 'Data', 'Produto' e 'Quantidade'. Seu desafio é carregar esses arquivos em DataFrames separados, combiná-los em um único DataFrame e, em seguida, calcular o total de vendas por produto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights para Dados\n",
    "Os dados muitas vezes estão espalhados por vários arquivos ou planilhas e a habilidade de combiná-los é crucial para análises abrangentes.\n",
    "\n",
    "Cenário comum onde dados de vendas estão distribuídos mensalmente em diferentes arquivos e precisam ser consolidados para análise anual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar múltiplos arquivos Excel, usando laços for junto com listas de nomes de arquivos ou padrões de correspondência de nomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Carregando todos os arquivos Excel no diretório atual\n",
    "arquivos_excel = glob.glob('dados_mes_*.xlsx')\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "for arquivo in arquivos_excel:\n",
    "    df = pd.read_excel(arquivo)\n",
    "    df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "\n",
    "print(df_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar pd.concat() para combinar DataFrames verticalmente (unindo dados) e pd.merge() para combinar horizontalmente (enriquecendo os dados com informações adicionais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo df_vendas e df_clientes como DataFrames previamente carregados\n",
    "df_combinado = pd.merge(df_vendas, df_clientes, on='cliente_id')\n",
    "print(df_combinado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar e tratar os dados após a combinação, como lidar com valores ausentes, duplicatas e inconsistências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores ausentes\n",
    "print(df_combinado.isnull().sum())\n",
    "\n",
    "# Removendo duplicatas\n",
    "df_combinado.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Db SQL\n",
    "Para dados armazenados em bancos de dados, Pandas pode executar consultas SQL diretamente e retornar o resultado como um DataFrame utilizando o método pd.read_sql_query()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Criando uma conexão ao banco de dados (exemplo SQLite)\n",
    "engine = create_engine('sqlite:///caminho/para/seu/banco_de_dados.db')\n",
    "\n",
    "# Carregando dados via consulta SQL\n",
    "df_sql = pd.read_sql_query(\"SELECT * FROM sua_tabela\", engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza e Preparação de Dados\n",
    "- Uma etapa fundamental no processo de análise de dados é a limpeza e preparação dos dados. Esta fase envolve tratar valores ausentes, remover duplicatas, filtrar dados, e fazer transformações necessárias para garantir que os dados estejam em um formato adequado para análise. Nesta aula, vamos explorar técnicas comuns de limpeza de dados usando Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Valores Ausentes\n",
    "- Valores ausentes são comuns em muitos conjuntos de dados e podem ser o resultado de erros de entrada de dados, falhas na coleta de dados, ou outras inconsistências. Pandas oferece várias formas de lidar com valores ausentes:\n",
    "\n",
    "  - Descartando valores ausentes: Usar dropna() para remover linhas ou colunas que contêm valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com valores ausentes\n",
    "df_limpo = df.dropna()\n",
    "\n",
    "# Removendo colunas com valores ausentes\n",
    "df_limpo = df.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preenchendo valores ausentes: Utilizar fillna() para substituir os valores ausentes por um valor específico, como a média da coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# Preenchendo valores ausentes com a média da coluna\n",
    "df['coluna'] = df['coluna'].fillna(df['coluna'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remoção de Duplicatas: Dados duplicados podem distorcer análises e resultados. Pandas torna fácil identificar e remover duplicatas com drop_duplicates().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicatas\n",
    "df_unico = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtragem de Dados\n",
    "Filtrar dados é um processo chave para focar em informações relevantes. Com Pandas, você pode usar condições booleanas para filtrar linhas que atendem a critérios específicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrando dados onde a coluna 'idade' é maior que 30\n",
    "df_filtrado = df[df['idade'] > 30]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformação de Dados\n",
    "  - Transformações são frequentemente necessárias para adequar os dados às necessidades da análise. Isso pode incluir a criação de novas colunas a partir de dados existentes, conversão de tipos de dados, entre outros.\n",
    "\n",
    "- Adicionando novas colunas: Você pode adicionar colunas baseadas em operações com colunas existentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criando uma nova coluna 'idade_dobrada'\n",
    "df['idade_dobrada'] = df['idade'] * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversão de tipos de dados: Use astype() para converter o tipo de dados de uma coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertendo a coluna 'idade' para float\n",
    "df['idade'] = df['idade'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exemplo Prático: \n",
    "Considerando um DataFrame df_vendas que contém dados de vendas, incluindo algumas colunas com valores ausentes e possíveis duplicatas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo valores ausentes na coluna 'quantidade' com a média\n",
    "df_vendas['quantidade'] = df_vendas['quantidade'].fillna(df_vendas['quantidade'].mean())\n",
    "\n",
    "# Removendo duplicatas\n",
    "df_vendas = df_vendas.drop_duplicates()\n",
    "\n",
    "# Filtrando vendas com valor maior que 500\n",
    "df_vendas_altas = df_vendas[df_vendas['valor'] > 500]\n",
    "\n",
    "# Adicionando uma nova coluna 'valor_total' (quantidade * valor)\n",
    "df_vendas['valor_total'] = df_vendas['quantidade'] * df_vendas['valor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação de Dados\n",
    "\n",
    "Depois de limpar e preparar os dados, o próximo passo é transformá-los para facilitar análises futuras.\n",
    "Operações de manipulação de dados, incluindo operações com colunas, funções de mapeamento, agrupamento, e agregação, utilizando a biblioteca Pandas.\n",
    "\n",
    "\n",
    "- Operações com Colunas: \n",
    "Adicionar, remover e modificar colunas: Pandas permite a manipulação flexível de colunas em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma nova coluna\n",
    "df['nova_coluna'] = df['coluna_existente'] * 10\n",
    "\n",
    "# Removendo uma coluna\n",
    "df = df.drop('coluna_para_remover', axis=1)\n",
    "\n",
    "# Modificar valores de uma coluna (por exemplo, aplicando uma função lambda)\n",
    "df['coluna_existente'] = df['coluna_existente'].apply(lambda x: x * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de Mapeamento\n",
    "apply() e map(): Estas funções permitem aplicar uma função ao longo de um eixo do DataFrame ou a uma Series, respectivamente, facilitando a transformação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apply() para aplicar uma função a todas as linhas de uma coluna\n",
    "df['coluna'] = df['coluna'].apply(lambda x: x + 100)\n",
    "\n",
    "# Usando map() para substituir valores em uma Series\n",
    "df['categoria'] = df['categoria'].map({'A': 1, 'B': 2, 'C': 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupamento e Agregação\n",
    "groupby(): Esta função é usada para agrupar dados com base em uma ou mais colunas e aplicar uma função de agregação (como soma, média, etc.) ao grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando dados pela coluna 'categoria' e calculando a média das outras colunas\n",
    "df_agrupado = df.groupby('categoria').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções de agregação: Após agrupar os dados, você pode aplicar várias funções de agregação para resumir os dados agrupados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando várias estatísticas agregadas após o agrupamento\n",
    "df_agrupado = df.groupby('categoria').agg({'coluna_numerica': ['mean', 'min', 'max']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Prático\n",
    "\n",
    "Suponha que temos um DataFrame df_vendas contendo colunas para data, categoria, valor_venda e quantidade. Vamos realizar algumas transformações para analisar esses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulando o DataFrame\n",
    "data = {\n",
    "    'data': pd.date_range('2021-01-01', periods=4),\n",
    "    'categoria': ['A', 'B', 'A', 'B'],\n",
    "    'valor_venda': [100, 200, 150, 300],\n",
    "    'quantidade': [1, 2, 2, 3]\n",
    "}\n",
    "df_vendas = pd.DataFrame(data)\n",
    "\n",
    "# Adicionando uma coluna 'valor_total'\n",
    "df_vendas['valor_total'] = df_vendas['valor_venda'] * df_vendas['quantidade']\n",
    "\n",
    "# Agrupando por 'categoria' e calculando o valor total de vendas por categoria\n",
    "vendas_por_categoria = df_vendas.groupby('categoria')['valor_total'].sum()\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(vendas_por_categoria)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise e Visualização de Dados\n",
    "\n",
    "Pandas integra-se bem com Matplotlib e Seaborn para visualização de dados, permitindo a análise visual dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histograma\n",
    "df['Idade'].hist()\n",
    "plt.title('Distribuição de Idades')\n",
    "plt.xlabel('Idade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras\n",
    "sns.barplot(x='Cidade', y='Idade', data=df)\n",
    "plt.title('Média de Idade por Cidade')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
